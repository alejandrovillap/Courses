{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d530248a-94fa-40e3-9806-4283f8b2fd23",
   "metadata": {},
   "source": [
    "# Data Science Tools and Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5e235b-7725-4e09-bc60-20744ebdbf39",
   "metadata": {},
   "source": [
    "In this notebook, Data Science Tools and Ecosystem are summarized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47bd622-1ba5-4950-ab11-df1568af1ae1",
   "metadata": {},
   "source": [
    "**Objectives:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee60565-008c-4438-9b50-f75cf8a875a5",
   "metadata": {},
   "source": [
    "### **Librerías para Data Science**\n",
    "- Pandas, NumPy, Scikit-learn, TensorFlow, etc.\n",
    "\n",
    "### **Lenguajes de Programación para Data Science**\n",
    "- Python, R, SQL.\n",
    "\n",
    "### **Herramientas para Data Science**\n",
    "- Jupyter Notebook, Google Colab, Anaconda, Tableau, Power BI.\n",
    "\n",
    "### **Cómo trabajar con Markdown en Jupyter**\n",
    "- Crear encabezados, listas, texto en negritas, entre otros.\n",
    "\n",
    "### **Cómo ejecutar programas en Jupyter**\n",
    "- Usar `Shift + Enter`, ejecutar celdas, y guardar el trabajo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27067d9-581b-4bbb-aebf-3c757a25b40d",
   "metadata": {},
   "source": [
    "## Author"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723ab6e-3a6f-406f-914c-53cd004f9246",
   "metadata": {},
   "source": [
    "Alejandro Villa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e5386-dc57-484e-bb22-383a8b5fb16c",
   "metadata": {},
   "source": [
    "## Some of the popular languages that Data Scientists use are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a028bf5c-0b0a-419b-8029-84bbc23b4efb",
   "metadata": {},
   "source": [
    "1. **Python**: Amplia variedad de librerías y frameworks para análisis de datos, visualización, machine learning y deep learning.\n",
    "2. **R**: Especializado en estadística y visualización de datos, con herramientas poderosas para análisis estadístico.\n",
    "3. **SQL**: Esencial para la gestión y consulta de bases de datos estructuradas, una habilidad clave para trabajar con grandes conjuntos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f2e3d-f650-44dc-8a19-8632ac38889b",
   "metadata": {},
   "source": [
    "## Some of the popular languages that Data Scientists use are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a777599a-7213-46f7-ba29-0a18fc1db0a7",
   "metadata": {},
   "source": [
    "# Librerías para Data Science\n",
    "\n",
    "## **Librerías para Manipulación de Datos**\n",
    "1. **Pandas**: Manipulación y análisis de datos en estructuras como DataFrames y Series.\n",
    "2. **NumPy**: Soporte para operaciones numéricas avanzadas y manejo de arreglos multidimensionales.\n",
    "3. **Dask**: Extensión de Pandas para trabajar con grandes conjuntos de datos que no caben en memoria.\n",
    "\n",
    "## **Librerías para Visualización**\n",
    "4. **Matplotlib**: Visualización básica y personalizada de gráficos.\n",
    "5. **Seaborn**: Basada en Matplotlib, simplifica la creación de gráficos estadísticos.\n",
    "6. **Plotly**: Visualización interactiva y personalizable (incluye gráficos 3D y Dashboards).\n",
    "7. **Bokeh**: Herramienta para gráficos interactivos para web.\n",
    "8. **Altair**: Librería declarativa basada en Vega para gráficos rápidos y limpios.\n",
    "\n",
    "## **Librerías para Machine Learning**\n",
    "9. **Scikit-learn**: Modelos de machine learning y herramientas de preprocesamiento.\n",
    "10. **TensorFlow**: Framework de deep learning desarrollado por Google.\n",
    "11. **PyTorch**: Framework flexible para deep learning desarrollado por Facebook.\n",
    "12. **XGBoost**: Algoritmo de boosting para problemas de clasificación y regresión.\n",
    "13. **LightGBM**: Alternativa a XGBoost, más rápida y eficiente con grandes datasets.\n",
    "14. **CatBoost**: Algoritmo de boosting optimizado para datos categóricos.\n",
    "\n",
    "## **Librerías para Ciencia Estadística**\n",
    "15. **Statsmodels**: Modelos estadísticos, pruebas y herramientas.\n",
    "16. **SciPy**: Paquete para cálculos científicos y técnicos (integración, optimización, estadísticas).\n",
    "\n",
    "## **Librerías para Procesamiento de Lenguaje Natural (NLP)**\n",
    "17. **NLTK**: Toolkit para procesamiento y análisis de texto.\n",
    "18. **spaCy**: Procesamiento avanzado de lenguaje natural con enfoque en rendimiento.\n",
    "19. **Transformers (Hugging Face)**: Modelos pre-entrenados como BERT, GPT, etc., para NLP.\n",
    "\n",
    "## **Librerías para Manejo y Visualización de Redes**\n",
    "20. **NetworkX**: Análisis y visualización de grafos y redes complejas.\n",
    "21. **Graph-tool**: Alternativa más eficiente para grafos grandes.\n",
    "\n",
    "## **Librerías para Trabajar con Datos Grandes**\n",
    "22. **PySpark**: API de Python para Apache Spark, ideal para big data.\n",
    "23. **Vaex**: Manejo de grandes datasets en memoria con excelente rendimiento.\n",
    "\n",
    "## **Librerías para Deep Learning Especializado**\n",
    "24. **Keras**: API de alto nivel para trabajar con TensorFlow.\n",
    "25. **OpenCV**: Procesamiento de imágenes y visión por computadora.\n",
    "26. **Fastai**: Framework simplificado para modelos de deep learning.\n",
    "\n",
    "## **Librerías para Trabajar con Series Temporales**\n",
    "27. **Statsmodels**: Modelos ARIMA y SARIMA para series temporales.\n",
    "28. **Prophet**: Herramienta de Facebook para pronósticos rápidos y precisos.\n",
    "29. **tsfresh**: Extracción automática de características de series temporales.\n",
    "\n",
    "## **Librerías para Web Scraping y Recolección de Datos**\n",
    "30. **Beautiful Soup**: Parsing de HTML para extraer datos.\n",
    "31. **Scrapy**: Framework para scraping de datos web más avanzado.\n",
    "32. **Selenium**: Automatización de navegadores para scraping dinámico.\n",
    "\n",
    "## **Librerías para Automatización de Tareas y Flujos**\n",
    "33. **Airflow**: Orquestación de flujos de trabajo en Data Science.\n",
    "34. **Luigi**: Similar a Airflow, para tareas de procesamiento de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29123c3-1cec-4e40-b1f5-7dd7d54f54f4",
   "metadata": {},
   "source": [
    "## Data Science Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f8b6f-be56-4f35-80b7-4ac9515fe8f6",
   "metadata": {},
   "source": [
    "1. **Jupyter Notebook**: Herramienta interactiva para escribir código, documentación y realizar análisis en un solo lugar.\n",
    "2. **Google Colab**: Versión basada en la nube de Jupyter, con acceso gratuito a GPUs y TPUs.\n",
    "3. **Anaconda**: Plataforma para gestionar paquetes y entornos de Python orientada a Data Science.\n",
    "4. **Tableau**: Herramienta de visualización de datos para crear dashboards interactivos.\n",
    "5. **Power BI**: Herramienta de Microsoft para análisis y visualización de datos empresariales.\n",
    "6. **Apache Spark**: Framework para procesamiento de grandes volúmenes de datos distribuido.\n",
    "7. **Hadoop**: Sistema para almacenar y procesar grandes cantidades de datos distribuidos.\n",
    "8. **Docker**: Tecnología para contenerizar aplicaciones, útil para entornos reproducibles en Data Science.\n",
    "9. **Git**: Sistema de control de versiones esencial para colaborar en proyectos.\n",
    "10. **Kaggle**: Plataforma para competiciones de Data Science y aprendizaje colaborativo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17a2e3-9799-4647-a45b-ec07fc618cf1",
   "metadata": {},
   "source": [
    "### Below are a few examples of evaluating arithmetic expressions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29088af-16dd-4450-a7d4-61220bd48841",
   "metadata": {},
   "source": [
    "This a simple arithmetic expression to mutiply then add integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "07e7110d-ab4a-4f4b-b6fe-a52b34b9508e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3*4)+5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065566b8-fb96-4664-83bc-fa6c483562ef",
   "metadata": {},
   "source": [
    "This will convert 200 minutes to hours by diving by 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3028d3c7-7ab9-4f2f-a998-14db15651add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333333333333335"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200/60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
